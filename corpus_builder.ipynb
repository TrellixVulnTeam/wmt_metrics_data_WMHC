{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_downloader\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "from logging import getLogger\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import argparse\n",
    "logger = data_downloader.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMT_IMPORTERS = {\n",
    "    \"15\": data_downloader.Importer1516,\n",
    "    \"16\": data_downloader.Importer1516,\n",
    "    \"17\": data_downloader.Importer17,\n",
    "    \"18\": data_downloader.Importer18,\n",
    "    \"19\": data_downloader.Importer19,\n",
    "    \"20\": data_downloader.Importer20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_flag(s):\n",
    "    \"\"\"\n",
    "    Parse boolean arguments from the command line.\n",
    "    \"\"\"\n",
    "    FALSY_STRINGS = {'off', 'false', '0'}\n",
    "    TRUTHY_STRINGS = {'on', 'true', '1'}\n",
    "    if s.lower() in FALSY_STRINGS:\n",
    "        return False\n",
    "    elif s.lower() in TRUTHY_STRINGS:\n",
    "        return True\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(\"Invalid value for a boolean flag!\")\n",
    "        \n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# path settings\n",
    "parser.add_argument('--target_path', type=str, default='/home/is/kosuke-t/scripts/make_data/wmt_metrics_data/data/wmt15-20_DA.json')\n",
    "parser.add_argument('--cache_path', type=str, default='/home/is/kosuke-t/scripts/make_data/wmt_metrics_data')\n",
    "parser.add_argument('--downloaded_dir', type=str, default='/home/is/kosuke-t/scripts/make_data/wmt_metrics_data/cache',\n",
    "                    help='for WMT20 submissions data. Must be specified when targeting WMT20')\n",
    "\n",
    "# others\n",
    "parser.add_argument('--years', type=str, default='15,16,17,18,19,20', help='separation must be given by \\\",\\\"')\n",
    "parser.add_argument('--target_language', type=str, default='*', help='if only english, then \\\"en\\\"')\n",
    "parser.add_argument('--include_unreliables', type=bool_flag, default=False,\n",
    "                    help='WMT20 has some unreliable data. This flag is set when including such data')\n",
    "parser.add_argument('--onlyMQM', type=bool_flag, default=False, \n",
    "                    help='only download and preprocessing MQM data. When both of onlyMQM and onlyPSQM are False, download DA data on WMT20')\n",
    "parser.add_argument('--onlyPSQM', type=bool_flag, default=False, \n",
    "                    help='only download and preprocessing PSQM data. When both of onlyMQM and onlyPSQM are False, download DA data on WMT20')\n",
    "parser.add_argument('--addMQM', type=bool_flag, default=False, help='build DA and MQM mixed data')\n",
    "parser.add_argument('--addPSQM', type=bool_flag, default=False, help='build DA and PSQM mixed data')\n",
    "parser.add_argument('--average_duplicates', type=bool_flag, default=True, \n",
    "                    help='Whether to take average of the scores annotated to the same sentences')\n",
    "parser.add_argument('--prevent_leaks', type=bool_flag, default=True, help='whether to allow for leaks among train and dev')\n",
    "parser.add_argument('--dev_ratio', type=float, default=0.1, help='development ratio')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.years = args.years.split(',')\n",
    "\n",
    "if args.addMQM:\n",
    "    assert (not args.onlyMQM) and (not args.onlyPSQM) and (not args.addPSQM) ,\\\n",
    "    'addMQM can stand only when other signals are off'\n",
    "if args.addPSQM:\n",
    "    assert (not args.onlyMQM) and (not args.onlyPSQM) and (not args.addMQM) ,\\\n",
    "    'addPSQM can stand only when other signals are off' \n",
    "\n",
    "if '20' in args.years:\n",
    "    assert os.path.isdir(args.downloaded_dir), 'Fetching 20\\'s data cannot be completed with this script.\\n'\\\n",
    "    'Download submission data from {} beforhand.\\n'\\\n",
    "    'Then, put the data folder inside the downloaded_dir of the arguments.'.format(data_downloader.WMT_LOCATIONS['20']['submissions'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wmt_dataset(target_file, rating_years, target_language):\n",
    "    \"\"\"Creates a JSONL file for a given set of years and a target language.\"\"\"\n",
    "    logger.info(\"*** Downloading ratings data from WMT.\")\n",
    "    assert target_file\n",
    "    assert not os.path.exists(args.target_path), \"Target file already exists. Aborting.\"\n",
    "    assert rating_years, \"No target year detected.\"\n",
    "    for year in rating_years:\n",
    "        assert year in WMT_IMPORTERS, \"No importer for year {}.\".format(year)\n",
    "    assert target_language\n",
    "    assert target_language == \"*\" or len(target_language) == 2, \"target_language must be a two-letter language code or `*`.\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory(dir=args.cache_path) as tmpdir:\n",
    "        logger.info(\"Using tmp directory: {}\".format(tmpdir))\n",
    "        args.cache_path = tmpdir\n",
    "        n_records_total = 0\n",
    "        tmp_file = os.path.join(tmpdir, \"tmp_ratings.json\")\n",
    "        \n",
    "        if '20' in rating_years:\n",
    "            logger.info('copying 20\\'s data to tmp directory...')\n",
    "            before_copy = os.path.join(args.downloaded_dir, data_downloader.WMT_LOCATIONS['20']['submissions'][0])\n",
    "            after_copy = os.path.join(tmpdir, data_downloader.WMT_LOCATIONS['20']['submissions'][0])\n",
    "            shutil.copytree(before_copy, after_copy)\n",
    "            logger.info('Done.')\n",
    "        \n",
    "        def fetch_and_generate(n_records_total):\n",
    "            # Builds an importer.\n",
    "            importer_class = WMT_IMPORTERS[year]\n",
    "            if year != '20':\n",
    "                importer = importer_class(year, tmp_file, tmpdir, args)\n",
    "            else:\n",
    "                if args.addMQM and args.onlyMQM:\n",
    "                    importer = importer_class(year, tmp_file.replace('.json', '_addMQM.json'), tmpdir, args, args.include_unreliables, args.onlyMQM, args.onlyPSQM)\n",
    "                elif args.addPSQM and args.onlyPSQM:\n",
    "                    importer = importer_class(year, tmp_file.replace('.json', '_addPSQM.json'), tmpdir, args, args.include_unreliables, args.onlyMQM, args.onlyPSQM)\n",
    "                else:\n",
    "                    importer = importer_class(year, tmp_file, tmpdir, args, args.include_unreliables, args.onlyMQM, args.onlyPSQM)\n",
    "            importer.fetch_files()\n",
    "            lang_pairs = importer.list_lang_pairs()\n",
    "            logger.info(\"Lang pairs found:\")\n",
    "            logger.info(\" \".join(lang_pairs))\n",
    "\n",
    "            for lang_pair in lang_pairs:\n",
    "\n",
    "                if target_language != \"*\" and not lang_pair.endswith(target_language):\n",
    "                    logger.info(\"Skipping language pair {}\".format(lang_pair))\n",
    "                    continue\n",
    "\n",
    "                logger.info(\"Generating records for {} and language pair {}\".format(year, lang_pair))\n",
    "                n_records = importer.generate_records_for_lang(lang_pair)\n",
    "                n_records_total += n_records\n",
    "            return n_records_total\n",
    "        \n",
    "        for year in rating_years:\n",
    "            logger.info(\"\\nProcessing ratings for year {}\".format(year))\n",
    "            \n",
    "            if year == '20' and args.addMQM:\n",
    "                args.onlyMQM = False\n",
    "                n_records_total = fetch_and_generate(n_records_total)\n",
    "                args.onlyMQM = True\n",
    "                n_records_total = fetch_and_generate(n_records_total)\n",
    "            elif year == '20' and args.addPSQM:\n",
    "                args.onlyPSQM = False\n",
    "                n_records_total = fetch_and_generate(n_records_total)\n",
    "                args.onlyPSQM = True\n",
    "                n_records_total = fetch_and_generate(n_records_total)\n",
    "            else:\n",
    "                n_records_total = fetch_and_generate(n_records_total)\n",
    "\n",
    "        logger.info(\"Done processing {} elements\".format(n_records_total))\n",
    "        logger.info(\"Copying temp file...\")\n",
    "        shutil.copyfile(tmp_file, target_file)\n",
    "        if args.addMQM:\n",
    "            shutil.copyfile(tmp_file.replace('.json', '_addMQM.json'), target_file.replace('.json', '_addMQM.json'))\n",
    "        elif args.addPSQM:\n",
    "            shutil.copyfile(tmp_file.replace('.json', '_addPSQM.json'), target_file.replace('.json', '_addPSQM.json'))\n",
    "        logger.info(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(target_file, remove_null_refs=True, average_duplicates=True):\n",
    "    \"\"\"Postprocesses a JSONL file of ratings downloaded from WMT.\"\"\"\n",
    "    logger.info(\"\\n*** Post-processing WMT ratings {}.\".format(target_file))\n",
    "    base_file = target_file + \"_raw\"\n",
    "    if not os.path.isfile(base_file):\n",
    "        assert os.path.isfile(target_file), \"WMT ratings file not found!\"\n",
    "        os.replace(target_file, base_file)\n",
    "\n",
    "    logger.info(\"Reading and processing wmt data...\")\n",
    "    with open(base_file, \"r\") as f:\n",
    "        ratings_df = pd.read_json(f, lines=True)\n",
    "    # ratings_df = ratings_df[[\"lang\", \"reference\", \"candidate\", \"rating\"]]\n",
    "    ratings_df.rename(columns={\"rating\": \"score\"}, inplace=True)\n",
    "\n",
    "    if remove_null_refs:\n",
    "        ratings_df = ratings_df[ratings_df[\"reference\"].notnull()]\n",
    "        assert not ratings_df.empty\n",
    "\n",
    "    if average_duplicates:\n",
    "        try:\n",
    "            ratings_df = ratings_df.groupby(by=[\"lang\", \"source\", \"candidate\", \"reference\"]).agg({\"score\": \"mean\",}).reset_index()\n",
    "        except:\n",
    "            logger.info('No duplicates.')\n",
    "\n",
    "    logger.info(\"Saving clean file.\")\n",
    "    with open(target_file, \"w+\") as f:\n",
    "        ratings_df.to_json(f, orient=\"records\", lines=True)\n",
    "    logger.info(\"Cleaning up old ratings file.\")\n",
    "    os.remove(base_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_no_leak(all_ratings_df, n_train):\n",
    "    \"\"\"Splits and shuffles such that there is no train/dev example with the same ref.\"\"\"\n",
    "\n",
    "    def is_split_leaky(ix):\n",
    "        return (all_ratings_df.iloc[ix].reference == all_ratings_df.iloc[ix-1].reference)\n",
    "\n",
    "    assert 0 < n_train < len(all_ratings_df.index)\n",
    "\n",
    "    # Clusters the examples by reference sentence.\n",
    "    sentences = all_ratings_df.reference.sample(frac=1, random_state=555).unique()\n",
    "    sentence_to_ix = {s: i for i, s in enumerate(sentences)}\n",
    "    all_ratings_df[\"__sentence_ix__\"] = [sentence_to_ix[s] for s in all_ratings_df.reference]\n",
    "    all_ratings_df = all_ratings_df.sort_values(by=\"__sentence_ix__\")\n",
    "    all_ratings_df.drop(columns=[\"__sentence_ix__\"], inplace=True)\n",
    "\n",
    "    # Moves the split point until there is no leakage.\n",
    "    split_ix = n_train\n",
    "    n_dev_sentences = len(all_ratings_df.iloc[split_ix:].reference.unique())\n",
    "    if n_dev_sentences == 1 and is_split_leaky(split_ix):\n",
    "        raise ValueError(\"Failed splitting data--not enough distinct dev sentences to prevent leak.\")\n",
    "    while is_split_leaky(split_ix):\n",
    "        split_ix += 1\n",
    "    if n_train != split_ix:\n",
    "        logger.info(\"Moved split point from {} to {} to prevent sentence leaking\".format(n_train, split_ix))\n",
    "\n",
    "    # Shuffles the train and dev sets separately.\n",
    "    train_ratings_df = all_ratings_df.iloc[:split_ix].copy()\n",
    "    train_ratings_df = train_ratings_df.sample(frac=1, random_state=555)\n",
    "    dev_ratings_df = all_ratings_df.iloc[split_ix:].copy()\n",
    "    dev_ratings_df = dev_ratings_df.sample(frac=1, random_state=555)\n",
    "    assert len(train_ratings_df) + len(dev_ratings_df) == len(all_ratings_df)\n",
    "\n",
    "    # Checks that there is no leakage.\n",
    "    train_sentences = train_ratings_df.reference.unique()\n",
    "    dev_sentences = dev_ratings_df.reference.unique()\n",
    "    logger.info(\"Using {} and {} unique sentences for train and dev.\".format(len(train_sentences), len(dev_sentences)))\n",
    "    assert not bool(set(train_sentences) & set(dev_sentences))\n",
    "\n",
    "    return train_ratings_df, dev_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_leaky(all_ratings_df, n_train):\n",
    "    \"\"\"Shuffles and splits the ratings allowing overlap in the ref sentences.\"\"\"\n",
    "    all_ratings_df = all_ratings_df.sample(frac=1, random_state=555)\n",
    "    all_ratings_df = all_ratings_df.reset_index(drop=True)\n",
    "    train_ratings_df = all_ratings_df.iloc[:n_train].copy()\n",
    "    dev_ratings_df = all_ratings_df.iloc[n_train:].copy()\n",
    "    assert len(train_ratings_df) + len(dev_ratings_df) == len(all_ratings_df)\n",
    "    return train_ratings_df, dev_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split(ratings_file,\n",
    "                  train_file=None,\n",
    "                  dev_file=None,\n",
    "                  dev_ratio=.1,\n",
    "                  prevent_leaks=True, \n",
    "                  addMQM=False, \n",
    "                  addPSQM=False):\n",
    "    \"\"\"Splits a JSONL WMT ratings file into train/dev.\"\"\"\n",
    "    logger.info(\"\\n*** Splitting WMT data in train/dev.\")\n",
    "\n",
    "    assert os.path.isfile(ratings_file), \"WMT ratings file not found!\"\n",
    "    if addMQM:\n",
    "        base_file = ratings_file.replace('.json', '_addMQM.json') + \"_raw\"\n",
    "        os.replace(ratings_file.replace('.json', '_addMQM.json'), base_file)\n",
    "    elif addPSQM:\n",
    "        base_file = ratings_file.replace('.json', '_addPSQM.json') + \"_raw\"\n",
    "        os.replace(ratings_file.replace('.json', '_addPSQM.json'), base_file)\n",
    "    else:\n",
    "        base_file = ratings_file + \"_raw\"\n",
    "        os.replace(ratings_file, base_file)\n",
    "        \n",
    "\n",
    "    logger.info(\"Reading wmt data...\")\n",
    "    with open(base_file, \"r\") as f:\n",
    "        ratings_df = pd.read_json(f, lines=True)\n",
    "\n",
    "    logger.info(\"Doing the shuffle / split.\")\n",
    "    n_rows, n_train = len(ratings_df), int((1 - dev_ratio) * len(ratings_df))\n",
    "    logger.info(\"Will attempt to set aside {} out of {} rows for dev.\".format(n_rows - n_train, n_rows))\n",
    "    if prevent_leaks:\n",
    "        train_df, dev_df = _shuffle_no_leak(ratings_df, n_train)\n",
    "    else:\n",
    "        train_df, dev_df = _shuffle_leaky(ratings_df, n_train)\n",
    "    logger.info(\"Split train and dev files with {} and {} records.\".format(len(train_df), len(dev_df)))\n",
    "    if addMQM or addPSQM:\n",
    "        with open(ratings_file, 'r') as f:\n",
    "            subject_df = pd.read_json(f, lines=True)\n",
    "        train_df = pd.concat([subject_df, train_df]).reset_index()\n",
    "    \n",
    "    logger.info(\"Saving clean file.\")\n",
    "    if not train_file:\n",
    "        if addMQM:\n",
    "            train_file = ratings_file.replace(\".json\", \"_addMQM_train.json\")\n",
    "        elif addPSQM:\n",
    "            train_file = ratings_file.replace(\".json\", \"_addPSQM_train.json\")\n",
    "        else:\n",
    "            train_file = ratings_file.replace(\".json\", \"_train.json\")\n",
    "    with open(train_file, \"w+\") as f:\n",
    "        train_df.to_json(f, orient=\"records\", lines=True)\n",
    "    if not dev_file:\n",
    "        if addMQM:\n",
    "            dev_file = ratings_file.replace(\".json\", \"_addMQM_dev.json\")\n",
    "        elif addPSQM:\n",
    "            dev_file = ratings_file.replace(\".json\", \"_addPSQM_dev.json\")\n",
    "        else:\n",
    "            dev_file = ratings_file.replace(\".json\", \"_dev.json\")\n",
    "    with open(dev_file, \"w+\") as f:\n",
    "        dev_df.to_json(f, orient=\"records\", lines=True)\n",
    "\n",
    "    logger.info(\"Cleaning up old ratings file.\")\n",
    "    logger.info(\"Created train and dev files with {} and {} records.\".format(len(train_df), len(dev_df)))\n",
    "    os.remove(base_file)\n",
    "    if addMQM or addPSQM:\n",
    "        os.remove(ratings_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wmt_dataset(args.target_path, args.years, args.target_language)\n",
    "postprocess(args.target_path, average_duplicates=args.average_duplicates)\n",
    "if args.addMQM:\n",
    "    postprocess(args.target_path.replace('.json', '_addMQM.json'), average_duplicates=args.average_duplicates)\n",
    "elif args.PSMQM:\n",
    "    postprocess(args.target_path.replace('.json', '_addPSQM.json'), average_duplicates=args.average_duplicates)\n",
    "if args.dev_ratio > 0.0:\n",
    "    shuffle_split(args.target_path, dev_ratio=args.dev_ratio, prevent_leaks=args.prevent_leaks, addMQM=args.addMQM, addPSQM=args.addPSQM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
