{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib\n",
    "import urllib.request\n",
    "import subprocess\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "import six\n",
    "# import tensorflow.compat.v1 as tf\n",
    "from distutils.dir_util import copy_tree\n",
    "from logging import getLogger, StreamHandler, DEBUG\n",
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(DEBUG)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMT_LOCATIONS = {'15': {\"eval_data\": (\"DAseg-wmt-newstest2015\", \n",
    "                                      \"DAseg-wmt-newstest2015.tar.gz\",\n",
    "                                      \"http://www.computing.dcu.ie/~ygraham/\")},\n",
    "                 '16': {\"eval_data\": (\"DAseg-wmt-newstest2016\", \n",
    "                                      \"DAseg-wmt-newstest2016.tar.gz\",\n",
    "                                      \"http://www.computing.dcu.ie/~ygraham/\")},\n",
    "                 '17': {\"full_package\":(\"wmt17-metrics-task-no-hybrids\", \n",
    "                                        \"wmt17-metrics-task-package.tgz\",\n",
    "                                        \"http://ufallab.ms.mff.cuni.cz/~bojar/\")},\n",
    "                 '18': {\"submissions\":(\"wmt18-metrics-task-nohybrids\", \n",
    "                                       \"wmt18-metrics-task-nohybrids.tgz\",\n",
    "                                       \"http://ufallab.ms.mff.cuni.cz/~bojar/wmt18/\"),\n",
    "                        \"eval_data\": (\"newstest2018-humaneval\", \n",
    "                                      \"newstest2018-humaneval.tar.gz\",\n",
    "                                      \"http://computing.dcu.ie/~ygraham/\")},\n",
    "                 '19': {\"submissions\": (\"wmt19-submitted-data-v3\",\n",
    "                                        \"wmt19-submitted-data-v3-txt-minimal.tgz\",\n",
    "                                        \"http://ufallab.ms.mff.cuni.cz/~bojar/wmt19/\"),\n",
    "                        \"eval_data\": (\"newstest2019-humaneval\", \n",
    "                                      \"newstest2019-humaneval.tar.gz\",\n",
    "                                      \"https://www.computing.dcu.ie/~ygraham/\")},\n",
    "                 '20': {\"submissions\":(\"WMT20_data\", \"\", \"https://drive.google.com/drive/folders/1n_alr6WFQZfw4dcAmyxow4V8FC67XD8p\"), \n",
    "                        \"eval_data\":(\"wmt20-metrics\", \"\", \"https://github.com/WMT-Metrics-task/wmt20-metrics\"), \n",
    "                        \"MQM\":(\"wmt-mqm-human-evaluation\", \"\", \"https://github.com/google/wmt-mqm-human-evaluation\"), \n",
    "                        'PSQM':(\"wmt-mqm-human-evaluation\", \"\", \"https://github.com/google/wmt-mqm-human-evaluation\")}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_lang_pair(lang_pair):\n",
    "    lang_expr = re.compile(\"([a-z]{2})-([a-z]{2})\")\n",
    "    match = lang_expr.match(lang_pair)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def postprocess_segment(segment):\n",
    "    \"\"\"Various string post-processing necessary to clean the records.\"\"\"\n",
    "    # Identifies NULL values.\n",
    "    if segment == \"NO REFERENCE AVAILABLE\\n\":\n",
    "        return None\n",
    "    # Removes trailing \\n's.\n",
    "    segment = segment.strip()\n",
    "    return segment\n",
    "\n",
    "def git_clone(url, destination_path):\n",
    "    return subprocess.check_call(['git', 'clone', url, destination_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@six.add_metaclass(abc.ABCMeta)\n",
    "class WMTImporter(object):\n",
    "    \"\"\"Base class for WMT Importers.\n",
    "\n",
    "    The aim of WMT importers is to fetch datafiles from the various WMT sources,\n",
    "    collect information (e.g., list language pairs) and aggregate them into\n",
    "    one big file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, year, target_path, cache_path, args):\n",
    "        self.year = year\n",
    "        self.location_info = WMT_LOCATIONS[year]\n",
    "        self.target_path = target_path\n",
    "        self.cache_path = cache_path\n",
    "        self.temp_directory = cache_path\n",
    "        self.args = args\n",
    "    \n",
    "    def open_tar(self, cache_tar_path):\n",
    "        logger.info(\"Untaring...\")\n",
    "        tar = tarfile.open(cache_tar_path)\n",
    "        if self.year == '17':\n",
    "            self.cache_path = os.path.join(self.cache_path, 'wmt17-metrics-task-package')\n",
    "            if not os.path.isdir(self.cache_path):\n",
    "                os.makedirs(self.cache_path)\n",
    "        tar.extractall(path=self.cache_path)\n",
    "        tar.close()\n",
    "        logger.info(\"Done.\")\n",
    "    \n",
    "    def fetch_files(self):\n",
    "        \"\"\"Downloads raw datafiles from various WMT sources.\"\"\"\n",
    "        cache = self.cache_path\n",
    "        if cache and not os.path.isdir(cache):\n",
    "            logger.info(\"Initializing cache {}\".format(cache))\n",
    "            os.makedirs(cache)\n",
    "        \n",
    "        for file_type in self.location_info:\n",
    "            folder_name, archive_name, url_prefix = self.location_info[file_type]\n",
    "            url = url_prefix + archive_name\n",
    "            cache_tar_path = os.path.join(cache, archive_name)\n",
    "            cache_untar_path = os.path.join(cache, archive_name).replace(\".tgz\", \"\", 1).replace(\".tar.gz\", \"\", 1)\n",
    "            if cache:\n",
    "                logger.info(\"Checking cached tar file {}.\".format(cache_tar_path))\n",
    "                if os.path.exists(cache_untar_path) :\n",
    "                    logger.info(\"Cache and untar directory found, skipping\")\n",
    "        #           tf.io.gfile.copy(cache_untar_path, os.path.join(self.temp_directory, os.path.basename(cache_untar_path)), overwrite=True)\n",
    "                    continue\n",
    "                if os.path.isfile(cache_tar_path):\n",
    "                    logger.info(\"Cache tar file found\")\n",
    "                    self.open_tar(cache_tar_path)\n",
    "\n",
    "            logger.info(\"File not found in cache.\")\n",
    "            logger.info(\"Downloading {} from {}\".format(folder_name, url))\n",
    "            urllib.request.urlretrieve(url, cache_tar_path)\n",
    "            logger.info(\"Done.\")\n",
    "            self.open_tar(cache_tar_path)\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        \"\"\"List all language pairs included in the WMT files for the target year.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def generate_records_for_lang(self, lang):\n",
    "        \"\"\"Consolidates all the files for a given language pair and year.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Housekeeping--we want to erase all the temp files created.\"\"\"\n",
    "        for file_type in self.location_info:\n",
    "            folder_name, archive_name, _ = self.location_info[file_type]\n",
    "\n",
    "            # Removes data folder\n",
    "            folder_path = os.path.join(self.temp_directory, folder_name)\n",
    "            logger.info(\"Removing\", folder_path)\n",
    "            try:\n",
    "                shutil.rmtree(folder_path)\n",
    "            except OSError:\n",
    "                logger.info(\"OS Error--skipping\")\n",
    "\n",
    "            # Removes downloaded archive\n",
    "            archive_path = os.path.join(self.temp_directory, archive_name)\n",
    "            logger.info(\"Removing\", archive_path)\n",
    "            try:\n",
    "                os.remove(archive_path)\n",
    "            except OSError:\n",
    "                logger.info(\"OS Error--skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importer1516(WMTImporter):\n",
    "    \"\"\"Importer for years 2015 and 2016.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(year, lang, source, reference, candidate, rating, seg_id, system):\n",
    "        \"\"\"Converts record to JSON.\"\"\"\n",
    "        json_dict = {\"year\": int(year),\n",
    "                     \"lang\": lang,\n",
    "                     \"source\": postprocess_segment(source),\n",
    "                     \"reference\": postprocess_segment(reference),\n",
    "                     \"candidate\": postprocess_segment(candidate),\n",
    "                     \"raw_rating\": None,\n",
    "                     \"rating\": float(rating.strip()),\n",
    "                     \"segment_id\": seg_id,\n",
    "                     \"system\": system,\n",
    "                     \"n_ratings\": None}\n",
    "        return json.dumps(json_dict)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_file_name(fname):\n",
    "        wmt_pattern = re.compile(r\"^DAseg\\.newstest([0-9]+)\\.[a-z\\-]+\\.([a-z\\-]+)\")\n",
    "        match = re.match(wmt_pattern, fname)\n",
    "        if match:\n",
    "            year, lang_pair = int(match.group(1)), match.group(2)\n",
    "            return year, lang_pair\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def get_full_folder_path(self):\n",
    "        \"\"\"Returns path of directory with all the extracted files.\"\"\"\n",
    "        file_type = \"eval_data\"\n",
    "        folder_name, _, _ = self.location_info[file_type]\n",
    "        folder = os.path.join(self.cache_path, folder_name)\n",
    "        return folder\n",
    "\n",
    "    def list_files_for_lang(self, lang):\n",
    "        \"\"\"Lists the full paths of all the files for a given language pair.\"\"\"\n",
    "        year = \"20\"+self.year\n",
    "        source_file = \"DAseg.newstest{}.source.{}\".format(str(year), lang)\n",
    "        reference_file = \"DAseg.newstest{}.reference.{}\".format(str(year), lang)\n",
    "        candidate_file = \"DAseg.newstest{}.mt-system.{}\".format(str(year), lang)\n",
    "        rating_file = \"DAseg.newstest{}.human.{}\".format(str(year), lang)\n",
    "        folder = self.get_full_folder_path()\n",
    "        return {\"source\": os.path.join(folder, source_file),\n",
    "                \"reference\": os.path.join(folder, reference_file),\n",
    "                \"candidate\": os.path.join(folder, candidate_file),\n",
    "                \"rating\": os.path.join(folder, rating_file)}\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        folder = self.get_full_folder_path()\n",
    "        file_names = os.listdir(folder)\n",
    "        file_data = [Importer1516.parse_file_name(f) for f in file_names]\n",
    "        lang_pairs = [lang_pair for year, lang_pair in file_data if year and lang_pair]\n",
    "        return list(set(lang_pairs))\n",
    "\n",
    "    def generate_records_for_lang(self, lang):\n",
    "        year = '20'+self.year\n",
    "        input_files = self.list_files_for_lang(lang)\n",
    "\n",
    "        # pylint: disable=g-backslash-continuation\n",
    "        with open(input_files[\"source\"], \"r\", encoding=\"utf-8\") as source_file, \\\n",
    "             open(input_files[\"reference\"], \"r\", encoding=\"utf-8\") as reference_file, \\\n",
    "             open(input_files[\"candidate\"], \"r\", encoding=\"utf-8\") as candidate_file, \\\n",
    "             open(input_files[\"rating\"], \"r\", encoding=\"utf-8\") as rating_file:\n",
    "            # pylint: enable=g-backslash-continuation\n",
    "            n_records = 0\n",
    "            with open(self.target_path, \"a+\") as dest_file:\n",
    "                for source, reference, candidate, rating in itertools.zip_longest(\n",
    "                    source_file, reference_file, candidate_file, rating_file):\n",
    "                    example = Importer1516.to_json(year, lang, source, reference, candidate, rating, n_records + 1, None)\n",
    "                    dest_file.write(example)\n",
    "                    dest_file.write(\"\\n\")\n",
    "                    n_records += 1\n",
    "                logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), year, lang))\n",
    "                return n_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importer17(WMTImporter):\n",
    "    \"\"\"Importer for year 2017.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Importer17, self).__init__(*args, **kwargs)\n",
    "        self.lang_pairs = None\n",
    "        self.temp_directory = os.path.join(self.cache_path, \"wmt17-metrics-task-package\")\n",
    "\n",
    "    def get_folder_path(self):\n",
    "        \"\"\"Returns path of directory with all the extracted files.\"\"\"\n",
    "        return self.temp_directory\n",
    "\n",
    "    def agg_ratings_path(self):\n",
    "        return os.path.join(self.temp_directory, \"manual-evaluation\", \"DA-seglevel.csv\")\n",
    "\n",
    "    def segments_path(self, subset=\"root\"):\n",
    "        \"\"\"Return the path to the source, reference, and candidate segments.\n",
    "\n",
    "        Args:\n",
    "          subset: one if \"root\", \"source\", \"reference\", or \"candidate\".\n",
    "\n",
    "        Returns:\n",
    "          Path to the relevant folder.\n",
    "        \"\"\"\n",
    "        assert subset in [\"root\", \"source\", \"reference\", \"candidate\"]\n",
    "        #     root_dir = os.path.join(self.temp_directory, \"extracted_wmt_package\")\n",
    "        root_dir = os.path.join(self.temp_directory, \"input\")\n",
    "        if subset == \"root\":\n",
    "            return root_dir\n",
    "\n",
    "        root_dir = os.path.join(root_dir, \"wmt17-metrics-task-no-hybrids\")\n",
    "        if subset == \"source\":\n",
    "            return os.path.join(root_dir, \"wmt17-submitted-data\", \"txt\", \"sources\")\n",
    "        elif subset == \"reference\":\n",
    "            return os.path.join(root_dir, \"wmt17-submitted-data\", \"txt\", \"references\")\n",
    "        elif subset == \"candidate\":\n",
    "            return os.path.join(root_dir, \"wmt17-submitted-data\", \"txt\", \"system-outputs\", \"newstest2017\")\n",
    "\n",
    "    def fetch_files(self):\n",
    "        \"\"\"Downloads the WMT eval files.\"\"\"\n",
    "        # Downloads the main archive.\n",
    "        super(Importer17, self).fetch_files()\n",
    "    \n",
    "        #Unpacks the segments.\n",
    "        package_path = self.get_folder_path()\n",
    "        segments_archive = os.path.join(package_path, \"input\", \"wmt17-metrics-task-no-hybrids.tgz\")\n",
    "        with (tarfile.open(segments_archive, \"r:gz\")) as tar:\n",
    "            tar.extractall(path=self.segments_path())\n",
    "        logger.info(\"Unpacked the segments to {}.\".format(self.segments_path()))\n",
    "\n",
    "        # Gets the language pair names.\n",
    "        ratings_path = self.agg_ratings_path()\n",
    "        lang_pairs = set()\n",
    "        with open(ratings_path, \"r\") as ratings_file:\n",
    "            for l in itertools.islice(ratings_file, 1, None):\n",
    "                lang = l.split(\" \")[0]\n",
    "                assert re.match(\"[a-z][a-z]-[a-z][a-z]\", lang)\n",
    "                lang_pairs.add(lang)\n",
    "        self.lang_pairs = list(lang_pairs)\n",
    "        logger.info(\"fetching Done\")\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        \"\"\"List all language pairs included in the WMT files for the target year.\"\"\"\n",
    "        if self.lang_pairs == None:\n",
    "            ratings_path = self.agg_ratings_path()\n",
    "            lang_pairs = set()\n",
    "            with open(ratings_path, \"r\") as ratings_file:\n",
    "                for l in itertools.islice(ratings_file, 1, None):\n",
    "                    lang = l.split(\" \")[0]\n",
    "                    assert re.match(\"[a-z][a-z]-[a-z][a-z]\", lang)\n",
    "                    lang_pairs.add(lang)\n",
    "            self.lang_pairs = list(lang_pairs)\n",
    "        return self.lang_pairs\n",
    "\n",
    "    def get_ref_segments(self, lang):\n",
    "        \"\"\"Fetches source and reference translation segments for language pair.\"\"\"\n",
    "        src_subfolder = self.segments_path(\"source\")\n",
    "        ref_subfolder = self.segments_path(\"reference\")\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        src_file = \"newstest2017-{}{}-src.{}\".format(src_lang, tgt_lang, src_lang)\n",
    "        ref_file = \"newstest2017-{}{}-ref.{}\".format(src_lang, tgt_lang, tgt_lang)\n",
    "        src_path = os.path.join(src_subfolder, src_file)\n",
    "        ref_path = os.path.join(ref_subfolder, ref_file)\n",
    "\n",
    "#         logger.info(\"Reading data from files {} and {}\".format(src_path, ref_path))\n",
    "        with open(src_path, \"r\", encoding=\"utf-8\") as f_src:\n",
    "            src_segments = f_src.readlines()\n",
    "        with open(ref_path, \"r\", encoding=\"utf-8\") as f_ref:\n",
    "            ref_segments = f_ref.readlines()\n",
    "        src_segments = [postprocess_segment(s) for s in src_segments]\n",
    "        ref_segments = [postprocess_segment(s) for s in ref_segments]\n",
    "#         logger.info(\"Read {} source and {} reference segments.\".format(len(src_segments), len(ref_segments)))\n",
    "        return src_segments, ref_segments\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_submission_file_name(fname):\n",
    "        \"\"\"Extracts system names from the name of submission files.\"\"\"\n",
    "        wmt_pattern = re.compile(r\"^newstest2017\\.([a-zA-Z0-9\\-\\.]+\\.[0-9]+)\\.[a-z]{2}-[a-z]{2}\")\n",
    "        match = re.match(wmt_pattern, fname)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_sys_segments(self, lang):\n",
    "        \"\"\"Builds a dictionary with the generated segments for each system.\"\"\"\n",
    "        # Gets all submission file paths.\n",
    "        root_folder = self.segments_path(\"candidate\")\n",
    "        folder = os.path.join(root_folder, lang)\n",
    "        all_files = os.listdir(folder)\n",
    "#         logger.info(\"Reading submission files from {}\".format(folder))\n",
    "\n",
    "        # Extracts the generated segments for each submission.\n",
    "        sys_segments = {}\n",
    "        for sys_file_name in all_files:\n",
    "            sys_name = Importer17.parse_submission_file_name(sys_file_name)\n",
    "            assert sys_name\n",
    "            sys_path = os.path.join(folder, sys_file_name)\n",
    "            with open(sys_path, \"r\", encoding=\"utf-8\") as f_sys:\n",
    "                sys_lines = f_sys.readlines()\n",
    "                sys_lines = [postprocess_segment(s) for s in sys_lines]\n",
    "                sys_segments[sys_name] = sys_lines\n",
    "\n",
    "#         logger.info(\"Read submissions from {} systems\".format(len(sys_segments.keys())))\n",
    "        return sys_segments\n",
    "\n",
    "    def parse_rating(self, line):\n",
    "        fields = line.split()\n",
    "        lang = fields[0]\n",
    "        sys_names = fields[2].split(\"+\")\n",
    "        seg_id = int(fields[3])\n",
    "        z_score = float(fields[4])\n",
    "        raw_score = None\n",
    "        for sys_name in sys_names:\n",
    "            yield lang, sys_name, seg_id, raw_score, z_score\n",
    "\n",
    "    def generate_records_for_lang(self, lang):\n",
    "        \"\"\"Consolidates all the files for a given language pair and year.\"\"\"\n",
    "        # Loads source, reference and system segments.\n",
    "        src_segments, ref_segments = self.get_ref_segments(lang)\n",
    "        sys_segments = self.get_sys_segments(lang)\n",
    "\n",
    "        # Streams the rating file and performs the join on-the-fly.\n",
    "        ratings_file_path = self.agg_ratings_path()\n",
    "#         logger.info(\"Reading file {}\".format(ratings_file_path))\n",
    "        n_records = 0\n",
    "        with open(ratings_file_path, \"r\", encoding=\"utf-8\") as f_ratings:\n",
    "            with open(self.target_path, \"a+\") as dest_file:\n",
    "                for line in itertools.islice(f_ratings, 1, None):\n",
    "                    for parsed_line in self.parse_rating(line):\n",
    "                        line_lang, sys_name, seg_id, raw_score, z_score = parsed_line\n",
    "                        if line_lang != lang:\n",
    "                            continue\n",
    "                        # The \"-1\" is necessary because seg_id starts counting at 1.\n",
    "                        src_segment = src_segments[seg_id - 1]\n",
    "                        ref_segment = ref_segments[seg_id - 1]\n",
    "                        sys_segment = sys_segments[sys_name][seg_id - 1]\n",
    "                        example = Importer18.to_json('20'+self.year, lang, src_segment,\n",
    "                                                     ref_segment, sys_segment, raw_score,\n",
    "                                                     z_score, seg_id, sys_name)\n",
    "                        dest_file.write(example)\n",
    "                        dest_file.write(\"\\n\")\n",
    "                        n_records += 1\n",
    "        logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), self.year, lang))\n",
    "        return n_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importer18(WMTImporter):\n",
    "    \"\"\"Importer for year 2018.\"\"\"\n",
    "\n",
    "    def parse_submission_file_name(self, fname):\n",
    "        \"\"\"Extracts system names from the name of submission files.\"\"\"\n",
    "        wmt_pattern = re.compile(r\"^newstest2018\\.([a-zA-Z0-9\\-\\.]+\\.[0-9]+)\\.[a-z]{2}-[a-z]{2}\")\n",
    "        match = re.match(wmt_pattern, fname)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def parse_eval_file_name(self, fname):\n",
    "        \"\"\"Extracts language pairs from the names of human rating files.\"\"\"\n",
    "        wmt_pattern = re.compile(r\"^ad-seg-scores-([a-z]{2}-[a-z]{2})\\.csv\")\n",
    "        match = re.match(wmt_pattern, fname)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        \"\"\"List all language pairs included in the WMT files for 2018.\"\"\"\n",
    "        folder_name, _, _ = self.location_info[\"eval_data\"]\n",
    "        subfolder = \"analysis\"\n",
    "        folder = os.path.join(self.temp_directory, folder_name, subfolder)\n",
    "        all_files = os.listdir(folder)\n",
    "        cand_lang_pairs = [self.parse_eval_file_name(fname) for fname in all_files]\n",
    "        # We need to remove None values in cand_lang_pair:\n",
    "        lang_pairs = [lang_pair for lang_pair in cand_lang_pairs if lang_pair]\n",
    "        return list(set(lang_pairs))\n",
    "\n",
    "    def get_ref_segments(self, lang):\n",
    "        \"\"\"Fetches source and reference translation segments for language pair.\"\"\"\n",
    "        folder, _, _ = self.location_info[\"submissions\"]\n",
    "        src_subfolder = os.path.join(\"sources\")\n",
    "        ref_subfolder = os.path.join(\"references\")\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        src_file = \"newstest2018-{}{}-src.{}\".format(src_lang, tgt_lang, src_lang)\n",
    "        ref_file = \"newstest2018-{}{}-ref.{}\".format(src_lang, tgt_lang, tgt_lang)\n",
    "        src_path = os.path.join(self.temp_directory, folder, src_subfolder, src_file)\n",
    "        ref_path = os.path.join(self.temp_directory, folder, ref_subfolder, ref_file)\n",
    "\n",
    "#         logger.info(\"Reading data from files {} and {}\".format(src_path, ref_path))\n",
    "        with open(src_path, \"r\", encoding=\"utf-8\") as f_src:\n",
    "            src_segments = f_src.readlines()\n",
    "        with open(ref_path, \"r\", encoding=\"utf-8\") as f_ref:\n",
    "            ref_segments = f_ref.readlines()\n",
    "\n",
    "        src_segments = [postprocess_segment(s) for s in src_segments]\n",
    "        ref_segments = [postprocess_segment(s) for s in ref_segments]\n",
    "\n",
    "        return src_segments, ref_segments\n",
    "\n",
    "    def get_sys_segments(self, lang):\n",
    "        \"\"\"Builds a dictionary with the generated segments for each system.\"\"\"\n",
    "        # Gets all submission file paths.\n",
    "        folder_name, _, _ = self.location_info[\"submissions\"]\n",
    "        subfolder = os.path.join(\"system-outputs\", \"newstest2018\")\n",
    "        folder = os.path.join(self.temp_directory, folder_name, subfolder, lang)\n",
    "        all_files = os.listdir(folder)\n",
    "#         logger.info(\"Reading submission files from {}\".format(folder))\n",
    "\n",
    "        # Extracts the generated segments for each submission.\n",
    "        sys_segments = {}\n",
    "        for sys_file_name in all_files:\n",
    "            if sys_file_name == '.ipynb_checkpoints':\n",
    "                continue\n",
    "            sys_name = self.parse_submission_file_name(sys_file_name)\n",
    "            assert sys_name\n",
    "            sys_path = os.path.join(folder, sys_file_name)\n",
    "            with open(sys_path, \"r\", encoding=\"utf-8\") as f_sys:\n",
    "                sys_lines = f_sys.readlines()\n",
    "                sys_lines = [postprocess_segment(s) for s in sys_lines]\n",
    "                sys_segments[sys_name] = sys_lines\n",
    "\n",
    "        return sys_segments\n",
    "\n",
    "    def get_ratings_path(self, lang):\n",
    "        folder, _, _ = self.location_info[\"eval_data\"]\n",
    "        subfolder = \"analysis\"\n",
    "        file_name = \"ad-seg-scores-{}.csv\".format(lang)\n",
    "        return os.path.join(self.temp_directory, folder, subfolder, file_name)\n",
    "\n",
    "    def parse_rating(self, rating_line):\n",
    "        rating_tuple = tuple(rating_line.split(\" \"))\n",
    "        # I have a feeling that the last field is the number of ratings\n",
    "        # but I'm not 100% sure .\n",
    "        sys_name, seg_id, raw_score, z_score, n_ratings = rating_tuple\n",
    "        seg_id = int(seg_id)\n",
    "        raw_score = float(raw_score)\n",
    "        z_score = float(z_score)\n",
    "        n_ratings = int(n_ratings)\n",
    "        return sys_name, seg_id, raw_score, z_score, n_ratings\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(year, lang, src_segment, ref_segment, sys_segment,\n",
    "                raw_score, z_score, seg_id, sys_name, n_ratings=0):\n",
    "        \"\"\"Converts record to JSON.\"\"\"\n",
    "        json_dict = {\"year\": year, \"lang\": lang, \"source\": src_segment, \n",
    "                     \"reference\": ref_segment, \"candidate\": sys_segment, \"raw_rating\": raw_score,\n",
    "                     \"rating\": z_score, \"segment_id\": seg_id, \"system\": sys_name,\n",
    "                     \"n_ratings\": n_ratings}\n",
    "        return json.dumps(json_dict)\n",
    "\n",
    "    def generate_records_for_lang(self, lang):\n",
    "        \"\"\"Consolidates all the files for a given language pair and year.\"\"\"\n",
    "\n",
    "        # Loads source, reference and system segments.\n",
    "        src_segments, ref_segments = self.get_ref_segments(lang)\n",
    "        sys_segments = self.get_sys_segments(lang)\n",
    "\n",
    "        # Streams the rating file and performs the join on-the-fly.\n",
    "        ratings_file_path = self.get_ratings_path(lang)\n",
    "#         logger.info(\"Reading file {}\".format(ratings_file_path))\n",
    "        n_records = 0\n",
    "        with open(ratings_file_path, \"r\", encoding=\"utf-8\") as f_ratings:\n",
    "            with open(self.target_path, \"a+\") as dest_file:\n",
    "                for line in itertools.islice(f_ratings, 1, None):\n",
    "                    line = line.rstrip()\n",
    "                    parsed_tuple = self.parse_rating(line)\n",
    "                    sys_name, seg_id, raw_score, z_score, n_ratings = parsed_tuple\n",
    "\n",
    "                    # Those weird rules come from the WMT 2019 DA2RR script.\n",
    "                    # Name of the script: seglevel-ken-rr.py, in Metrics results package.\n",
    "                    if sys_name == \"UAlacant_-_NM\":\n",
    "                        sys_name = \"UAlacant_-_NMT+RBMT.6722\"\n",
    "                    if sys_name == \"HUMAN\":\n",
    "                        continue\n",
    "                    if sys_name == \"RBMT.6722\":\n",
    "                        continue\n",
    "\n",
    "                    # The following rules were added by me to unblock WMT2019:\n",
    "                    if sys_name == \"Helsinki-NLP.6889\":\n",
    "                        sys_name = \"Helsinki_NLP.6889\"\n",
    "                    if sys_name == \"Facebook-FAIR.6937\":\n",
    "                        sys_name = \"Facebook_FAIR.6937\"\n",
    "                    if sys_name == \"Facebook-FAIR.6937\":\n",
    "                        sys_name = \"Facebook_FAIR.6937\"\n",
    "                    if sys_name == \"DBMS-KU-KKEN.6726\":\n",
    "                        sys_name = \"DBMS-KU_KKEN.6726\"\n",
    "                    if sys_name == \"Ju-Saarland.6525\":\n",
    "                        sys_name = \"Ju_Saarland.6525\"\n",
    "                    if sys_name == \"aylien-mt-gu-en-multilingual.6826\":\n",
    "                        sys_name = \"aylien_mt_gu-en_multilingual.6826\"\n",
    "                    if sys_name == \"rug-kken-morfessor.6677\":\n",
    "                        sys_name = \"rug_kken_morfessor.6677\"\n",
    "                    if sys_name == \"talp-upc-2019-kken.6657\":\n",
    "                        sys_name = \"talp_upc_2019_kken.6657\"\n",
    "                    if sys_name == \"Frank-s-MT.6127\":\n",
    "                        sys_name = \"Frank_s_MT.6127\"\n",
    "\n",
    "                    if lang == \"de-cs\" and sys_name == \"Unsupervised.6935\":\n",
    "                        sys_name = \"Unsupervised.de-cs.6935\"\n",
    "                    if lang == \"de-cs\" and sys_name == \"Unsupervised.6929\":\n",
    "                        sys_name = \"Unsupervised.de-cs.6929\"\n",
    "\n",
    "                    # The \"-1\" is necessary because seg_id starts counting at 1.\n",
    "                    src_segment = src_segments[seg_id - 1]\n",
    "                    ref_segment = ref_segments[seg_id - 1]\n",
    "                    sys_segment = sys_segments[sys_name][seg_id - 1]\n",
    "                    if not src_segment or not sys_segment:\n",
    "                        logger.info(\"* Missing value!\")\n",
    "                        logger.info(\"* System: {}\".format(sys_name))\n",
    "                        logger.info(\"* Segment:\" + str(seg_id))\n",
    "                        logger.info(\"* Source segment:\" + src_segment)\n",
    "                        logger.info(\"* Sys segment:\" + sys_segment)\n",
    "                        logger.info(\"* Parsed line:\" + line)\n",
    "                        logger.info(\"* Lang:\" + lang)\n",
    "                    example = Importer18.to_json(self.year, lang, src_segment, \n",
    "                                                 ref_segment, sys_segment, raw_score, \n",
    "                                                 z_score, seg_id, sys_name, n_ratings)\n",
    "                    dest_file.write(example)\n",
    "                    dest_file.write(\"\\n\")\n",
    "                    n_records += 1\n",
    "        logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), self.year, lang))\n",
    "        return n_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importer19(Importer18):\n",
    "    \"\"\"Importer for WMT19 Metrics challenge.\"\"\"\n",
    "\n",
    "    def parse_rating(self, rating_line):\n",
    "        rating_tuple = tuple(rating_line.split(\" \"))\n",
    "        # I have a feeling that the last field is the number of ratings\n",
    "        # but I'm not 100% sure.\n",
    "        sys_name, seg_id, raw_score, z_score, n_ratings = rating_tuple\n",
    "\n",
    "        # For some reason, all the systems for pair zh-en have an extra suffix.\n",
    "        if sys_name.endswith(\"zh-en\"):\n",
    "            sys_name = sys_name[:-6]\n",
    "\n",
    "        seg_id = int(seg_id)\n",
    "        raw_score = float(raw_score)\n",
    "        z_score = float(z_score)\n",
    "        n_ratings = int(n_ratings)\n",
    "        return sys_name, seg_id, raw_score, z_score, n_ratings\n",
    "\n",
    "    def parse_submission_file_name(self, fname):\n",
    "        \"\"\"Extracts system names from the name of submission files.\"\"\"\n",
    "\n",
    "        # I added those rules to unblock the pipeline.\n",
    "        if fname == \"newstest2019.Unsupervised.de-cs.6929.de-cs\":\n",
    "            return \"Unsupervised.de-cs.6929\"\n",
    "        elif fname == \"newstest2019.Unsupervised.de-cs.6935.de-cs\":\n",
    "            return \"Unsupervised.de-cs.6935\"\n",
    "\n",
    "        wmt_pattern = re.compile(r\"^newstest2019\\.([a-zA-Z0-9\\-\\.\\_\\+]+\\.[0-9]+)\\.[a-z]{2}-[a-z]{2}\")\n",
    "        match = re.match(wmt_pattern, fname)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        \"\"\"List all language pairs included in the WMT files for 2019.\"\"\"\n",
    "        folder_name, _, _ = self.location_info[\"eval_data\"]\n",
    "        folder = os.path.join(self.temp_directory, folder_name, \"*\", \"analysis\", \"ad-seg-scores-*.csv\")\n",
    "        all_full_paths = glob.glob(folder)\n",
    "        all_files = [os.path.basename(f) for f in all_full_paths]\n",
    "        cand_lang_pairs = [self.parse_eval_file_name(fname) for fname in all_files]\n",
    "        # We need to remove None values in cand_lang_pair:\n",
    "        lang_pairs = [lang_pair for lang_pair in cand_lang_pairs if lang_pair]\n",
    "        return list(set(lang_pairs))\n",
    "\n",
    "    def get_ratings_path(self, lang):\n",
    "        folder, _, _ = self.location_info[\"eval_data\"]\n",
    "\n",
    "        # The pair zh-en has two versions in the WMT 2019 human eval folder.\n",
    "        if lang == \"zh-en\":\n",
    "            path = os.path.join(self.temp_directory, folder, \n",
    "                                \"turkle-sntlevel-humaneval-newstest2019\", \"analysis\", \"ad-seg-scores-zh-en.csv\")\n",
    "            return path\n",
    "\n",
    "        file_name = \"ad-seg-scores-{}.csv\".format(lang)\n",
    "        folder = os.path.join(self.temp_directory, folder, \"*\", \"analysis\", \"ad-seg-scores-*.csv\")\n",
    "        all_files = glob.glob(folder)\n",
    "        for cand_file in all_files:\n",
    "            if cand_file.endswith(file_name):\n",
    "                return cand_file\n",
    "        raise ValueError(\"Can't find ratings for lang {}\".format(lang))\n",
    "\n",
    "    def get_ref_segments(self, lang):\n",
    "        \"\"\"Fetches source and reference translation segments for language pair.\"\"\"\n",
    "        folder, _, _ = self.location_info[\"submissions\"]\n",
    "        src_subfolder = os.path.join(\"txt\", \"sources\")\n",
    "        ref_subfolder = os.path.join(\"txt\", \"references\")\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        src_file = \"newstest2019-{}{}-src.{}\".format(src_lang, tgt_lang, src_lang)\n",
    "        ref_file = \"newstest2019-{}{}-ref.{}\".format(src_lang, tgt_lang, tgt_lang)\n",
    "        src_path = os.path.join(self.temp_directory, folder, src_subfolder, src_file)\n",
    "        ref_path = os.path.join(self.temp_directory, folder, ref_subfolder, ref_file)\n",
    "\n",
    "#         logger.info(\"Reading data from files {} and {}\".format(src_path, ref_path))\n",
    "        with open(src_path, \"r\", encoding=\"utf-8\") as f_src:\n",
    "            src_segments = f_src.readlines()\n",
    "        with open(ref_path, \"r\", encoding=\"utf-8\") as f_ref:\n",
    "            ref_segments = f_ref.readlines()\n",
    "\n",
    "        src_segments = [postprocess_segment(s) for s in src_segments]\n",
    "        ref_segments = [postprocess_segment(s) for s in ref_segments]\n",
    "\n",
    "        return src_segments, ref_segments\n",
    "\n",
    "    def get_sys_segments(self, lang):\n",
    "        \"\"\"Builds a dictionary with the generated segments for each system.\"\"\"\n",
    "        # Gets all submission file paths.\n",
    "        folder_name, _, _ = self.location_info[\"submissions\"]\n",
    "        subfolder = os.path.join(\"txt\", \"system-outputs\", \"newstest2019\")\n",
    "        folder = os.path.join(self.temp_directory, folder_name, subfolder, lang)\n",
    "        all_files = os.listdir(folder)\n",
    "#         logger.info(\"Reading submission files from {}\".format(folder))\n",
    "\n",
    "        # Extracts the generated segments for each submission.\n",
    "        sys_segments = {}\n",
    "        for sys_file_name in all_files:\n",
    "            sys_name = self.parse_submission_file_name(sys_file_name)\n",
    "            assert sys_name\n",
    "            sys_path = os.path.join(folder, sys_file_name)\n",
    "            with open(sys_path, \"r\", encoding=\"utf-8\") as f_sys:\n",
    "                sys_lines = f_sys.readlines()\n",
    "                sys_lines = [postprocess_segment(s) for s in sys_lines]\n",
    "                sys_segments[sys_name] = sys_lines\n",
    "\n",
    "        return sys_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importer20(Importer18):\n",
    "    \"\"\"Importer for WMT20 Metrics challenge.\"\"\"\n",
    "    \n",
    "    def __init__(self, year, target_path, cache_path, args, include_unreliables, onlyMQM=False, onlyPSQM=False):\n",
    "        super(Importer20, self).__init__(year, target_path, cache_path, args)\n",
    "        self.include_unreliables = include_unreliables\n",
    "        self.onlyMQM = onlyMQM\n",
    "        self.onlyPSQM = onlyPSQM\n",
    "        assert not (onlyMQM and onlyPSQM), \"only one of onlyMQM or onlyPSQM can stand\"\n",
    "    \n",
    "    def open_tar(self, tar_path, open_dir):\n",
    "        logger.info(\"Untaring...\")\n",
    "        tar = tarfile.open(tar_path)\n",
    "        tar.extractall(path=open_dir)\n",
    "        tar.close()\n",
    "        logger.info(\"Done.\")\n",
    "    \n",
    "    def fetch_files(self):\n",
    "        \"\"\"Downloads raw datafiles from various WMT sources.\"\"\"\n",
    "        cache = self.cache_path\n",
    "        \n",
    "        if cache and not os.path.isdir(cache):\n",
    "            logger.info(\"Initializing cache {}\".format(cache))\n",
    "            os.makedirs(cache)\n",
    "        \n",
    "        for file_type in self.location_info:\n",
    "            if self.onlyMQM:\n",
    "                if file_type in ['submissions', 'eval_data', 'PSQM']:\n",
    "                    continue\n",
    "            elif self.onlyPSQM:\n",
    "                if file_type in ['submissions', 'eval_data', 'MQM']:\n",
    "                    continue\n",
    "            \n",
    "            folder_name, _, url = self.location_info[file_type]\n",
    "            cache_untar_path = os.path.join(cache, folder_name)\n",
    "            \n",
    "            if cache:\n",
    "                logger.info(\"Checking cached tar file {}.\".format(cache_untar_path))\n",
    "                if os.path.exists(cache_untar_path) :\n",
    "                    if file_type == 'submissions':\n",
    "                        tars = os.path.join(cache_untar_path, '*.tar.gz')\n",
    "                        tar_paths = glob.glob(tars)\n",
    "                        untar_paths = [path.replace(\".tar.gz\", \"\", 1) for path in tar_paths]\n",
    "                        for tar_path, untar_paths in zip(tar_paths, untar_paths):\n",
    "                            if not os.path.exists(untar_paths):\n",
    "                                self.open_tar(tar_path, cache_untar_path)\n",
    "                            else:\n",
    "                                logger.info(\"Cache and untar directory found, skipping\")\n",
    "                    else:\n",
    "                        logger.info(\"Cache and untar directory found, skipping\")\n",
    "                    continue\n",
    "            logger.info(\"File not found in cache.\")\n",
    "            if file_type == 'submissions':\n",
    "                logger.info(\"Cannot download {} with this script. Download from {}\".format(folder_name, url))\n",
    "                exit(-1)\n",
    "            logger.info(\"Downloading {} from {}\".format(folder_name, url))\n",
    "            git_clone(url, cache_untar_path)\n",
    "            logger.info(\"Done.\")  \n",
    "    \n",
    "    def parse_rating(self, rating_line, lang):\n",
    "        rating_tuple = tuple(rating_line.split(\" \"))\n",
    "        # I have a feeling that the last field is the number of ratings\n",
    "        # but I'm not 100% sure.\n",
    "        sys_name, seg_id, raw_score, z_score, n_ratings = rating_tuple\n",
    "        \n",
    "        # en-zh has unknown seg_id probablly tagged with other format name\n",
    "        if lang in ['en-zh', 'en-ja', 'en-iu', 'en-cs', 'en-ta', 'en-ru', 'en-de', 'en-pl']:\n",
    "            seg_id = seg_id.split('_')[-1] \n",
    "        \n",
    "        try:\n",
    "            seg_id = int(seg_id)\n",
    "            raw_score = float(raw_score)\n",
    "            z_score = float(z_score)\n",
    "            n_ratings = int(n_ratings)\n",
    "        except:\n",
    "            logger.info(lang)\n",
    "            logger.info(rating_line)\n",
    "        return sys_name, seg_id, raw_score, z_score, n_ratings\n",
    "\n",
    "    def parse_submission_file_name(self, fname, lang):\n",
    "        \"\"\"Extracts system names from the name of submission files.\"\"\"\n",
    "\n",
    "        # I added those rules to unblock the pipeline.\n",
    "\n",
    "        sys_name = fname.replace(\"newstest2020.{}.\".format(lang), \"\", 1).replace(\".txt\", \"\", 1)\n",
    "\n",
    "        return sys_name\n",
    "\n",
    "    def list_lang_pairs(self):\n",
    "        \"\"\"List all language pairs included in the WMT files for 2020.\"\"\"\n",
    "        if self.onlyMQM or self.onlyPSQM:\n",
    "            return ['en-de', 'zh-en']\n",
    "        \n",
    "        folder_name, _, _ = self.location_info[\"eval_data\"]\n",
    "        folder = os.path.join(self.temp_directory, folder_name, \"manual-evaluation\", \"DA\", \"ad-seg-scores-*.csv\")\n",
    "        all_full_paths = glob.glob(folder)\n",
    "        all_files = [os.path.basename(f) for f in all_full_paths]\n",
    "        cand_lang_pairs = [self.parse_eval_file_name(fname) for fname in all_files]\n",
    "        # We need to remove None values in cand_lang_pair:\n",
    "        lang_pairs = [lang_pair for lang_pair in cand_lang_pairs if lang_pair]\n",
    "        return list(set(lang_pairs))\n",
    "\n",
    "    def get_ratings_path(self, lang):\n",
    "        folder, _, _ = self.location_info[\"eval_data\"]\n",
    "\n",
    "        file_name = \"ad-seg-scores-{}.csv\".format(lang)\n",
    "        folder = os.path.join(self.temp_directory, folder, \"manual-evaluation\", \"DA\", \"ad-seg-scores-*.csv\")\n",
    "        all_files = glob.glob(folder)\n",
    "        for cand_file in all_files:\n",
    "            if cand_file.endswith(file_name):\n",
    "                return cand_file\n",
    "        raise ValueError(\"Can't find ratings for lang {}\".format(lang))\n",
    "\n",
    "    def get_ref_segments(self, lang):\n",
    "        \"\"\"Fetches source and reference translation segments for language pair.\"\"\"\n",
    "        folder, _, _ = self.location_info[\"submissions\"]\n",
    "        src_subfolder = os.path.join(\"txt\", \"sources\")\n",
    "        ref_subfolder = os.path.join(\"txt\", \"references\")\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        src_file = \"newstest2020-{}{}-src.{}.txt\".format(src_lang, tgt_lang, src_lang)\n",
    "        ref_file = \"newstest2020-{}{}-ref.{}.txt\".format(src_lang, tgt_lang, tgt_lang)\n",
    "        src_path = os.path.join(self.temp_directory, folder, src_subfolder, src_file)\n",
    "        ref_path = os.path.join(self.temp_directory, folder, ref_subfolder, ref_file)\n",
    "\n",
    "#         logger.info(\"Reading data from files {} and {}\".format(src_path, ref_path))\n",
    "        with open(src_path, \"r\", encoding=\"utf-8\") as f_src:\n",
    "            src_segments = f_src.readlines()\n",
    "        with open(ref_path, \"r\", encoding=\"utf-8\") as f_ref:\n",
    "            ref_segments = f_ref.readlines()\n",
    "\n",
    "        src_segments = [postprocess_segment(s) for s in src_segments]\n",
    "        ref_segments = [postprocess_segment(s) for s in ref_segments]\n",
    "\n",
    "        return src_segments, ref_segments\n",
    "\n",
    "    def get_sys_segments(self, lang):\n",
    "        \"\"\"Builds a dictionary with the generated segments for each system.\"\"\"\n",
    "        # Gets all submission file paths.\n",
    "        folder_name, _, _ = self.location_info[\"submissions\"]\n",
    "        subfolder = os.path.join(\"txt\", \"system-outputs\")\n",
    "        folder = os.path.join(self.temp_directory, folder_name, subfolder, lang)\n",
    "        all_files = os.listdir(folder)\n",
    "#         logger.info(\"Reading submission files from {}\".format(folder))\n",
    "\n",
    "        # Extracts the generated segments for each submission.\n",
    "        sys_segments = {}\n",
    "        for sys_file_name in all_files:\n",
    "            sys_name = self.parse_submission_file_name(sys_file_name, lang)\n",
    "            assert sys_name\n",
    "            sys_path = os.path.join(folder, sys_file_name)\n",
    "            with open(sys_path, \"r\", encoding=\"utf-8\") as f_sys:\n",
    "                sys_lines = f_sys.readlines()\n",
    "                sys_lines = [postprocess_segment(s) for s in sys_lines]\n",
    "                sys_segments[sys_name] = sys_lines\n",
    "\n",
    "        return sys_segments\n",
    "    \n",
    "    def parse_mqm(self, line, lang):\n",
    "        rating_tuple = tuple(line.split(\"\\t\"))\n",
    "        system, doc, doc_id, seg_id, rater, source, target, category, severity = rating_tuple\n",
    "        \n",
    "        score = 0.0\n",
    "        assert severity in ['Major', 'Minor', 'Neutral', 'no-error'], 'unknown severity:{}'.format(severity)\n",
    "\n",
    "        if severity == 'Major':\n",
    "            if category == 'Non-translation!':\n",
    "                score = -25.0\n",
    "            else:\n",
    "                score = -5.0\n",
    "        elif severity == 'Minor':\n",
    "            if category == 'Fluency/Punctuation':\n",
    "                score = -0.1\n",
    "            else:\n",
    "                score = -1.0\n",
    "        \n",
    "        try:\n",
    "            doc_id = int(doc_id)\n",
    "            seg_id = int(seg_id)\n",
    "        except:\n",
    "            logger.info(lang)\n",
    "            logger.info(line)\n",
    "        return system, doc, doc_id, seg_id, rater, source, target, category, severity, score\n",
    "    \n",
    "    def get_mqm_segments(self, lang):\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        folder_name, _, _ = self.location_info[\"MQM\"]\n",
    "        file = os.path.join(self.temp_directory, folder_name, \"{}{}\".format(src_lang, tgt_lang), \"mqm_newstest2020_{}{}.tsv\".format(src_lang, tgt_lang))\n",
    "        rater_score = {}\n",
    "        seg_scores = {}\n",
    "        with open(file, mode='r', encoding='utf-8') as r:\n",
    "            for line in itertools.islice(r, 1, None):\n",
    "                line = line.rstrip()\n",
    "                system, doc, doc_id, seg_id, rater, source, target, category, severity, score = self.parse_mqm(line, lang)\n",
    "                if rater not in rater_score:\n",
    "                    rater_score[rater] = {'score':[score], \n",
    "                                          'source':[source.rstrip()],\n",
    "                                          'target':[target.rstrip()], \n",
    "                                          'system':[system], \n",
    "                                          'seg_id':[seg_id]}\n",
    "                else:\n",
    "                    rater_score[rater]['score'].append(score)\n",
    "                    rater_score[rater]['source'].append(source.rstrip())\n",
    "                    rater_score[rater]['target'].append(target.rstrip())\n",
    "                    rater_score[rater]['system'].append(system)\n",
    "                    rater_score[rater]['seg_id'].append(seg_id)\n",
    "        for rater in rater_score.keys():\n",
    "            rater_score[rater]['z_score'] = list(preprocessing.scale(rater_score[rater]['score']))\n",
    "        for rater in rater_score.keys():\n",
    "            for seg_id, src, tgt, score, z_score, system in zip(rater_score[rater]['seg_id'], \n",
    "                                                                rater_score[rater]['source'], \n",
    "                                                                rater_score[rater]['target'], \n",
    "                                                                rater_score[rater]['score'], \n",
    "                                                                rater_score[rater]['z_score'], \n",
    "                                                                rater_score[rater]['system']):\n",
    "                sys_id = (system, seg_id)\n",
    "                if sys_id not in seg_scores:\n",
    "                    seg_scores[sys_id] = {'rater':[rater],\n",
    "                                          'score':[score], \n",
    "                                          'z_score':[z_score],\n",
    "                                          'source':[source],\n",
    "                                          'target':[target]}\n",
    "                else:\n",
    "                    seg_scores[sys_id]['rater'].append(rater)\n",
    "                    seg_scores[sys_id]['score'].append(score)\n",
    "                    seg_scores[sys_id]['z_score'].append(z_score)\n",
    "                    seg_scores[sys_id]['source'].append(source)\n",
    "                    seg_scores[sys_id]['target'].append(target)\n",
    "        for sys_id in seg_scores.keys():\n",
    "            seg_scores[sys_id]['z_mean_score'] = np.mean(seg_scores[sys_id]['z_score'])\n",
    "        \n",
    "        return rater_score, seg_scores\n",
    "                \n",
    "    def get_mqm_avg_segments(self, lang, seg_scores):\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        folder_name, _, _ = self.location_info[\"MQM\"]\n",
    "        file = os.path.join(self.temp_directory, folder_name, \"{}{}\".format(src_lang, tgt_lang), \"mqm_newstest2020_{}{}.avg_seg_scores.tsv\".format(src_lang, tgt_lang))\n",
    "        with open(file, mode='r', encoding='utf-8') as r:\n",
    "            for line in itertools.islice(r, 1, None):\n",
    "                line = line.rstrip()\n",
    "                system, mqm_avg_score, seg_id = tuple(line.split(' '))\n",
    "                sys_id = (system, int(seg_id))\n",
    "                seg_scores[sys_id]['raw_score'] = mqm_avg_score\n",
    "        return seg_scores\n",
    "    \n",
    "    def generate_mqm_records_for_lang(self, lang):\n",
    "        rater_score, seg_scores = self.get_mqm_segments(lang)\n",
    "        src_segments, ref_segments = self.get_ref_segments(lang)\n",
    "        sys_segments = self.get_sys_segments(lang)\n",
    "        seg_scores = self.get_mqm_avg_segments(lang, seg_scores)\n",
    "        \n",
    "        n_records = 0\n",
    "        skipped_n_records = 0\n",
    "        with open(self.target_path, \"a+\") as dest_file:\n",
    "            for sys_id in seg_scores.keys():\n",
    "                sys_name, seg_id = sys_id\n",
    "                raw_score = seg_scores[sys_id]['raw_score']\n",
    "                z_score = seg_scores[sys_id]['z_score']\n",
    "                \n",
    "                # The \"-1\" is necessary because seg_id starts counting at 1.\n",
    "                src_segment = src_segments[seg_id - 1]\n",
    "                ref_segment = ref_segments[seg_id - 1]\n",
    "                if sys_name not in sys_segments:\n",
    "                    print(sys_name, lang)\n",
    "                else:\n",
    "                    sys_segment = sys_segments[sys_name][seg_id - 1]\n",
    "\n",
    "                if not src_segment or not sys_segment:\n",
    "                    logger.info(\"* Missing value!\")\n",
    "                    logger.info(\"* System: {}\".format(sys_name))\n",
    "                    logger.info(\"* Segment:\" + str(seg_id))\n",
    "                    logger.info(\"* Source segment:\" + src_segment)\n",
    "                    logger.info(\"* Sys segment:\" + sys_segment)\n",
    "                    logger.info(\"* Parsed line:\" + line)\n",
    "                    logger.info(\"* Lang:\" + lang)\n",
    "                example = Importer18.to_json(self.year, lang, src_segment, \n",
    "                                             ref_segment, sys_segment, raw_score, \n",
    "                                             z_score, seg_id, sys_name)\n",
    "                dest_file.write(example)\n",
    "                dest_file.write(\"\\n\")\n",
    "                n_records += 1\n",
    "        logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), self.year, lang))\n",
    "        logger.info(\"Skipped {} records of {}'s {}\".format(str(skipped_n_records), self.year, lang))\n",
    "        return n_records\n",
    "    \n",
    "    def parse_psqm(self, line, lang):\n",
    "        rating_tuple = tuple(line.split(\"\\t\"))\n",
    "        system, doc, doc_id, seg_id, rater, source, target, score = rating_tuple\n",
    "        \n",
    "        score = 0.0\n",
    "        try:\n",
    "            doc_id = int(doc_id)\n",
    "            seg_id = int(seg_id)\n",
    "        except:\n",
    "            logger.info(lang)\n",
    "            logger.info(line)\n",
    "        return system, doc, doc_id, seg_id, rater, source, target, score\n",
    "    \n",
    "    def get_psqm_segments(self, lang):\n",
    "        src_lang, tgt_lang = separate_lang_pair(lang)\n",
    "        folder_name, _, _ = self.location_info[\"PSQM\"]\n",
    "        file = os.path.join(self.temp_directory, folder_name, \"{}{}\".format(src_lang, tgt_lang), \"psqm_newstest2020_{}{}.tsv\".format(src_lang, tgt_lang))\n",
    "        rater_score = {}\n",
    "        seg_scores = {}\n",
    "        with open(file, mode='r', encoding='utf-8') as r:\n",
    "            for line in itertools.islice(r, 1, None):\n",
    "                line = line.rstrip()\n",
    "                system, doc, doc_id, seg_id, rater, source, target, score = self.parse_psqm(line, lang)\n",
    "                if rater not in rater_score:\n",
    "                    rater_score[rater] = {'score':[score], \n",
    "                                          'source':[source.rstrip()],\n",
    "                                          'target':[target.rstrip()], \n",
    "                                          'system':[system], \n",
    "                                          'seg_id':[seg_id]}\n",
    "                else:\n",
    "                    rater_score[rater]['score'].append(score)\n",
    "                    rater_score[rater]['source'].append(source.rstrip())\n",
    "                    rater_score[rater]['target'].append(target.rstrip())\n",
    "                    rater_score[rater]['system'].append(system)\n",
    "                    rater_score[rater]['seg_id'].append(seg_id)\n",
    "        for rater in rater_score.keys():\n",
    "            rater_score[rater]['z_score'] = list(preprocessing.scale(rater_score[rater]['score']))\n",
    "        for rater in rater_score.keys():\n",
    "            for seg_id, src, tgt, score, z_score, system in zip(rater_score[rater]['seg_id'], \n",
    "                                                                rater_score[rater]['source'], \n",
    "                                                                rater_score[rater]['target'], \n",
    "                                                                rater_score[rater]['score'], \n",
    "                                                                rater_score[rater]['z_score'], \n",
    "                                                                rater_score[rater]['system']):\n",
    "                sys_id = (system, seg_id)\n",
    "                if sys_id not in seg_scores:\n",
    "                    seg_scores[sys_id] = {'rater':[rater],\n",
    "                                          'score':[score], \n",
    "                                          'z_score':[z_score],\n",
    "                                          'source':[source],\n",
    "                                          'target':[target]}\n",
    "                else:\n",
    "                    seg_scores[sys_id]['rater'].append(rater)\n",
    "                    seg_scores[sys_id]['score'].append(score)\n",
    "                    seg_scores[sys_id]['z_score'].append(z_score)\n",
    "                    seg_scores[sys_id]['source'].append(source)\n",
    "                    seg_scores[sys_id]['target'].append(target)\n",
    "        for sys_id in seg_scores.keys():\n",
    "            seg_scores[sys_id]['z_mean_score'] = np.mean(seg_scores[sys_id]['z_score'])\n",
    "        \n",
    "        return rater_score, seg_scores\n",
    "    \n",
    "    \n",
    "    def generate_psqm_records_for_lang(self, lang):\n",
    "        rater_score, seg_scores = self.get_psqm_segments(lang)\n",
    "        src_segments, ref_segments = self.get_ref_segments(lang)\n",
    "        sys_segments = self.get_sys_segments(lang)\n",
    "        \n",
    "        n_records = 0\n",
    "        skipped_n_records = 0\n",
    "        with open(self.target_path, \"a+\") as dest_file:\n",
    "            for sys_id in seg_scores.keys():\n",
    "                sys_name, seg_id = sys_id\n",
    "                raw_score = 'n/a'\n",
    "                z_score = seg_scores[sys_id]['z_score']\n",
    "                \n",
    "                # The \"-1\" is necessary because seg_id starts counting at 1.\n",
    "                src_segment = src_segments[seg_id - 1]\n",
    "                ref_segment = ref_segments[seg_id - 1]\n",
    "                if sys_name not in sys_segments:\n",
    "                    print(sys_name, lang)\n",
    "                else:\n",
    "                    sys_segment = sys_segments[sys_name][seg_id - 1]\n",
    "\n",
    "                if not src_segment or not sys_segment:\n",
    "                    logger.info(\"* Missing value!\")\n",
    "                    logger.info(\"* System: {}\".format(sys_name))\n",
    "                    logger.info(\"* Segment:\" + str(seg_id))\n",
    "                    logger.info(\"* Source segment:\" + src_segment)\n",
    "                    logger.info(\"* Sys segment:\" + sys_segment)\n",
    "                    logger.info(\"* Parsed line:\" + line)\n",
    "                    logger.info(\"* Lang:\" + lang)\n",
    "                example = Importer18.to_json(self.year, lang, src_segment, \n",
    "                                             ref_segment, sys_segment, raw_score, \n",
    "                                             z_score, seg_id, sys_name)\n",
    "                dest_file.write(example)\n",
    "                dest_file.write(\"\\n\")\n",
    "                n_records += 1\n",
    "        logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), self.year, lang))\n",
    "        logger.info(\"Skipped {} records of {}'s {}\".format(str(skipped_n_records), self.year, lang))\n",
    "        \n",
    "        return n_records\n",
    "    \n",
    "    \n",
    "    def generate_records_for_lang(self, lang):\n",
    "        \"\"\"Consolidates all the files for a given language pair and year.\"\"\"\n",
    "        \n",
    "        if self.onlyMQM:\n",
    "            n_records = self.generate_mqm_records_for_lang(lang)\n",
    "            return n_records\n",
    "        elif self.onlyPSQM:\n",
    "            n_records = self.generate_psqm_records_for_lang(lang)\n",
    "            return n_records\n",
    "\n",
    "        # Loads source, reference and system segments.\n",
    "        src_segments, ref_segments = self.get_ref_segments(lang)\n",
    "        sys_segments = self.get_sys_segments(lang)\n",
    "\n",
    "        # Streams the rating file and performs the join on-the-fly.\n",
    "        ratings_file_path = self.get_ratings_path(lang)\n",
    "#         logger.info(\"Reading file {}\".format(ratings_file_path))\n",
    "        n_records = 0\n",
    "        skipped_n_records = 0\n",
    "        \n",
    "        if lang in ['en-zh', 'en-ja', 'en-iu', 'en-cs', 'en-ta', 'en-ru', 'en-de', 'en-pl'] and (not self.include_unreliables):\n",
    "            return 0\n",
    "        \n",
    "        with open(ratings_file_path, \"r\", encoding=\"utf-8\") as f_ratings:\n",
    "            with open(self.target_path, \"a+\") as dest_file:\n",
    "                for line in itertools.islice(f_ratings, 1, None):\n",
    "                    line = line.rstrip()\n",
    "                    parsed_tuple = self.parse_rating(line, lang)\n",
    "                    sys_name, seg_id, raw_score, z_score, n_ratings = parsed_tuple\n",
    "                    \n",
    "                    if sys_name == 'HUMAN.0' and lang == 'de-en':\n",
    "                        skipped_n_records += 1\n",
    "                        continue\n",
    "                    if sys_name == 'HUMAN.0' and lang == 'zh-en':\n",
    "                        skipped_n_records += 1\n",
    "                        continue\n",
    "                    if sys_name == 'HUMAN.0' and lang == 'ru-en':\n",
    "                        skipped_n_records += 1\n",
    "                        continue\n",
    "                    if sys_name == 'HUMAN-B':\n",
    "                        sys_name == 'Human-B.0'\n",
    "                    if sys_name == 'Huoshan-Translate.1470' and lang == 'ps-en':\n",
    "                        sys_name = 'Huoshan_Translate.1470'\n",
    "                    if sys_name == 'Facebook-AI.729' and lang == 'iu-en':\n",
    "                        sys_name = 'Facebook_AI.729'\n",
    "                    if sys_name == 'Huawei-TSC.1533' and lang == 'ps-en':\n",
    "                        sys_name = 'Huawei_TSC.1533'\n",
    "                    if sys_name == 'UQAM-TanLe.520' and lang == 'iu-en':\n",
    "                        sys_name = 'UQAM_TanLe.520'\n",
    "                    if sys_name == 'HUMAN' and lang == 'ps-en':\n",
    "                        sys_name = 'Human-A.0'\n",
    "                    if sys_name == 'NICT-Kyoto.1220' and lang == 'iu-en':\n",
    "                        sys_name = 'NICT_Kyoto.1220'\n",
    "                    if sys_name == 'HUMAN' and lang == 'iu-en':\n",
    "                        sys_name = 'Human-A.0'\n",
    "                    if sys_name == 'Huawei-TSC.1539' and lang == 'km-en':\n",
    "                        sys_name = 'Huawei_TSC.1539'\n",
    "                    if sys_name == 'Huoshan-Translate.651' and lang == 'km-en':\n",
    "                        sys_name = 'Huoshan_Translate.651'\n",
    "                    if sys_name == 'HUMAN' and lang == 'km-en':\n",
    "                        sys_name = 'Human-A.0'\n",
    "                    \n",
    "                    # The \"-1\" is necessary because seg_id starts counting at 1.\n",
    "                    src_segment = src_segments[seg_id - 1]\n",
    "                    ref_segment = ref_segments[seg_id - 1]\n",
    "                    sys_segment = sys_segments[sys_name][seg_id - 1]\n",
    "                    \n",
    "                    if not src_segment or not sys_segment:\n",
    "                        logger.info(\"* Missing value!\")\n",
    "                        logger.info(\"* System: {}\".format(sys_name))\n",
    "                        logger.info(\"* Segment:\" + str(seg_id))\n",
    "                        logger.info(\"* Source segment:\" + src_segment)\n",
    "                        logger.info(\"* Sys segment:\" + sys_segment)\n",
    "                        logger.info(\"* Parsed line:\" + line)\n",
    "                        logger.info(\"* Lang:\" + lang)\n",
    "                    example = Importer18.to_json(self.year, lang, src_segment, \n",
    "                                                 ref_segment, sys_segment, raw_score, \n",
    "                                                 z_score, seg_id, sys_name, n_ratings)\n",
    "                    dest_file.write(example)\n",
    "                    dest_file.write(\"\\n\")\n",
    "                    n_records += 1\n",
    "        logger.info(\"Processed {} records of {}'s {}\".format(str(n_records), self.year, lang))\n",
    "        logger.info(\"Skipped {} records of {}'s {}\".format(str(skipped_n_records), self.year, lang))\n",
    "        return n_records\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer = Importer20('20', \n",
    "#                       '/home/is/kosuke-t/scripts/make_data/wmt_metrics_data/data/wmt2020_mqm.json', \n",
    "#                       '/home/is/kosuke-t/scripts/make_data/wmt_metrics_data/cache',\n",
    "#                       args=None,\n",
    "#                       include_unreliables=False,\n",
    "#                       onlyMQM=False, \n",
    "#                       onlyPSQM=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking cached tar file /home/is/kosuke-t/scripts/make_data/wmt_metrics/cache/wmt-mqm-human-evaluation.\n",
      "Cache and untar directory found, skipping\n"
     ]
    }
   ],
   "source": [
    "# importer.fetch_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl-en\n",
      "de-en\n",
      "ru-en\n",
      "ps-en\n",
      "iu-en\n",
      "ta-en\n",
      "en-ja\n",
      "en-cs\n",
      "en-zh\n",
      "en-iu\n",
      "en-de\n",
      "zh-en\n",
      "km-en\n",
      "en-pl\n",
      "cs-en\n",
      "en-ru\n",
      "en-ta\n",
      "ja-en\n"
     ]
    }
   ],
   "source": [
    "# for lang in importer.list_lang_pairs():\n",
    "#     print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://drive.google.com/drive/folders/1n_alr6WFQZfw4dcAmyxow4V8FC67XD8p'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
